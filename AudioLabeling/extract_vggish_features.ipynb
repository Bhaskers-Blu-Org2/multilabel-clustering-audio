{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0807 13:51:11.151993 140275452749568 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jams\n",
    "import numpy as np\n",
    "import scipy\n",
    "import h5py\n",
    "#import sklearn\n",
    "#import librosa\n",
    "import os\n",
    "import glob\n",
    "#import matplotlib.pyplot as plt\n",
    "#import sklearn.neural_network\n",
    "#import sklearn.ensemble\n",
    "import pickle\n",
    "import extract_features as extract_features\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filepath = os.path.join(\"C:/Users/t-anmend/Documents/UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(open(metadata_filepath,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1 = df[df['fold']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1 = fold_1[fold_1['end']-fold_1['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1_names = fold1['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_1_txt_path,fold1_names[i]) for i in range(len(fold1_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_1_txt_path,'fold_1_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_2 = df[df['fold']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_2.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold2 = fold_2[fold_2['end']-fold_2['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold2_names = fold2['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_2_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_2_txt_path,fold2_names[i]) for i in range(len(fold2_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_2_txt_path,'fold_2_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_3 = df[df['fold']==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_3.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold3 = fold_3[fold_3['end']-fold_3['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold3_names = fold3['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_3_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_3_txt_path,fold3_names[i]) for i in range(len(fold3_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_3_txt_path,'fold_3_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_4 = df[df['fold']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_4.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_4.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold4 = fold_4[fold_4['end']-fold_4['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold4_names = fold4['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_4_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_4_txt_path,fold4_names[i]) for i in range(len(fold4_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_4_txt_path,'fold_4_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_5 = df[df['fold']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_5.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_5.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold5 = fold_5[fold_5['end']-fold_5['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold5_names = fold5['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_5_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_5_txt_path,fold5_names[i]) for i in range(len(fold5_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_5_txt_path,'fold_5_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_6 = df[df['fold']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_6.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_6.iloc[[26]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold6 = fold_6[fold_6['end']-fold_6['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold6_names = fold6['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_6_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_6_txt_path,fold6_names[i]) for i in range(len(fold6_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_6_txt_path,'fold_6_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_7 = df[df['fold']==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_7.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_7.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold7 = fold_7[fold_7['end']-fold_7['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold7_names = fold7['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_7_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_7_txt_path,fold7_names[i]) for i in range(len(fold7_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_7_txt_path,'fold_7_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8 = df[df['fold']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold8 = fold_8[fold_8['end']-fold_8['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold8_names = fold8['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_8_txt_path,fold8_names[i]) for i in range(len(fold8_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_8_txt_path,'fold_8_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_9 = df[df['fold']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_9.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_9.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold9 = fold_9[fold_9['end']-fold_9['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold9_names = fold9['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_9_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_9_txt_path,fold9_names[i]) for i in range(len(fold9_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_9_txt_path,'fold_9_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files fold 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_10 = df[df['fold']==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_10.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_10.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold10 = fold_10[fold_10['end']-fold_10['start'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold10_names = fold10['slice_file_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_10_txt_path = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(fold_10_txt_path,fold10_names[i]) for i in range(len(fold10_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(fold_10_txt_path,'fold_10_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(files,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Scaper data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaper_path = \"/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfiles = [os.path.join(scaper_path, f) for f in os.listdir(scaper_path) if os.path.splitext(os.path.join(scaper_path, f))[1] == '.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wavfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform3161.wav'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(scaper_path,'paths_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(wavfiles,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/t-anmend/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfiles = [os.path.join(path, f) for f in os.listdir(path) if os.path.splitext(os.path.join(path, f))[1] == '.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(os.path.join(path,'paths_txt.txt'), \"wb\")\n",
    "\n",
    "pickle.dump(wavfiles,file)               \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/t-anmend/test/TUT-SED-synthetic-2016-mix-1_01.wav',\n",
       " '/home/t-anmend/test/TUT-SED-synthetic-2016-mix-1_02.wav',\n",
       " '/home/t-anmend/test/TUT-SED-synthetic-2016-mix-1_00.wav']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Urban Sound 8k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_1_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_1_folder,'fold_1_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold1_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold1_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold1)):\n",
    "    \n",
    "    classid.append(int(fold1.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_1_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_1_features.txt'),'rb') as f:\n",
    "    features_file_fold1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_1_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_1_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_2_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_2_folder,'fold_2_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold2_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold2_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold2)):\n",
    "    \n",
    "    classid.append(int(fold2.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_2_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_2_features.txt'),'rb') as f:\n",
    "    features_file_fold2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_2_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_2_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_3_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_3_folder,'fold_3_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold3_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold3_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold3)):\n",
    "    \n",
    "    classid.append(int(fold3.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_3_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_3_features.txt'),'rb') as f:\n",
    "    features_file_fold3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_3_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_3_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_4_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_4_folder,'fold_4_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold4_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold4_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold4)):\n",
    "    \n",
    "    classid.append(int(fold4.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_4_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_4_features.txt'),'rb') as f:\n",
    "    features_file_fold4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_4_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_4_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_5_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_5_folder,'fold_5_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold5_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold5_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold5)):\n",
    "    \n",
    "    classid.append(int(fold5.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_5_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_5_features.txt'),'rb') as f:\n",
    "    features_file_fold5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_5_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_5_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_6_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_6_folder,'fold_6_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold6_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold6_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold6)):\n",
    "    \n",
    "    classid.append(int(fold6.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_6_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_6_features.txt'),'rb') as f:\n",
    "    features_file_fold6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold6[26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_6_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_6_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_7_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_7_folder,'fold_7_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold7_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold7_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold7)):\n",
    "    \n",
    "    classid.append(int(fold7.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_7_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_7_features.txt'),'rb') as f:\n",
    "    features_file_fold7 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_7_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_7_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_8_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_8_folder,'fold_8_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold8_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold8_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold8)):\n",
    "    \n",
    "    classid.append(int(fold8.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_8_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_8_features.txt'),'rb') as f:\n",
    "    features_file_fold8 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_8_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_8_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_9_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_9_folder,'fold_9_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold9_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold9_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold9)):\n",
    "    \n",
    "    classid.append(int(fold9.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_9_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_9_features.txt'),'rb') as f:\n",
    "    features_file_fold9 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_9_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_9_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_10_folder = os.path.join(\"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\fold10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(fold_10_folder,'fold_10_txt.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold10_features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\\\\' + 'fold10_features.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[4]['features_z'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "for i in range(len(fold10)):\n",
    "    \n",
    "    classid.append(int(fold10.iloc[[i]]['classID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'][~np.all(features[i]['features_z'] == 0, axis=1)])\n",
    "        \n",
    "    row_list.append(classid[i])\n",
    "    row_list.append(files[i])\n",
    "        \n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_folder = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\UrbanSound8K\\\\audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_10_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_10_features.txt'),'rb') as f:\n",
    "    features_file_fold10 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file_fold10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_10_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(features_folder,'fold_10_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features SCAPER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"C:\\\\Users\\\\t-anmend\\\\Documents\\\\train_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/\"+'train_paths_labels12000.txt'),'rb') as f:\n",
    "    #f.seek(0)\n",
    "    mylist = pickle.load(f)\n",
    "\n",
    "files = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    files.append(mylist[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/uniform/soundscape_train_1_uniform0.wav',\n",
       " ['drilling', 'jackhammer']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/uniform/soundscape_train_1_uniform0.wav'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "print(len(mylist))\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 19:41:05.518947 140608263800576 deprecation_wrapper.py:119] From /home/t-anmend/AudioLabeling/extract_features.py:63: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]W0805 19:41:05.596848 140608263800576 deprecation_wrapper.py:119] From /home/t-anmend/AudioLabeling/audioset/vggish_slim.py:76: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0805 19:41:05.599143 140608263800576 deprecation_wrapper.py:119] From /home/t-anmend/AudioLabeling/audioset/vggish_slim.py:78: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0805 19:41:05.916736 140608263800576 deprecation.py:323] From /home/t-anmend/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0805 19:41:06.419024 140608263800576 deprecation_wrapper.py:119] From /home/t-anmend/AudioLabeling/audioset/vggish_slim.py:120: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0805 19:41:06.420748 140608263800576 deprecation_wrapper.py:119] From /home/t-anmend/AudioLabeling/audioset/vggish_slim.py:127: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0805 19:41:06.442565 140608263800576 deprecation.py:323] From /home/t-anmend/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform0.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform10.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform100.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1000.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1001.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1002.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1003.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1004.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1005.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1006.wav features 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-50c037b2755c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_vggish_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:\\\\Users\\\\t-anmend\\\\Documents\\\\train_1\\\\'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train1_features3000.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AudioLabeling/extract_features.py\u001b[0m in \u001b[0;36mextract_vggish_embeddings\u001b[0;34m(input_filepaths, output_file, xdim, ydim, start_index)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'u1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_features.extract_vggish_embeddings(files,os.path.join('C:\\\\Users\\\\t-anmend\\\\Documents\\\\train_1\\\\' + 'train1_features3000.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform3161.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4754.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform2487.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4587.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1261.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4614.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform2110.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1484.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform105.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform3698.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1062.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform2332.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform3642.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform2431.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4651.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4666.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4909.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform697.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1077.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1985.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform2563.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform774.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4668.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform297.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform3325.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1055.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4066.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform266.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform1888.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform509.wav features 10.0\n",
      "/home/t-anmend/UrbanSound8K/soundscapes/train_5000/uniform/soundscape_train_1_uniform4005.wav features 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d1c73f83ecff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_vggish_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwavfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/t-anmend/UrbanSound8K/soundscapes/train_5000/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'features.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AudioLabeling/extract_features.py\u001b[0m in \u001b[0;36mextract_vggish_embeddings\u001b[0;34m(input_filepaths, output_file, xdim, ydim, start_index)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfeatures_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0memb_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scaper/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extract_features.extract_vggish_embeddings(wavfiles,os.path.join(\"/home/t-anmend/UrbanSound8K/soundscapes/train_5000/\" + 'features.h5'))\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = h5py.File(os.path.join('/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/' + 'train1_features12000.h5'),  \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(features_file.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"features\": shape (12000,), type \"|V12192\">"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[9999]['features_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features[0]['features_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0]['features_z'][~np.all(features[0]['features_z'] == 0, axis=1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/t-anmend/UrbanSound8K/soundscapes/train_5000/train_paths_labels.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(\"/home/t-anmend/UrbanSound8K/soundscapes/train_5000/\"+'train_paths_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classid = []\n",
    "\n",
    "for i in range(len(mylist)):\n",
    "    \n",
    "    classid.append(mylist[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engine_idling',\n",
       " 'air_conditioner',\n",
       " 'air_conditioner',\n",
       " 'jackhammer',\n",
       " 'children_playing']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "\n",
    "start = 0\n",
    "\n",
    "for i in range(len(features)):\n",
    "    \n",
    "    row_list = []\n",
    "    row_list.append(features[i]['features_z'])\n",
    "        \n",
    "    row_list.append(classid[start])\n",
    "    row_list.append(files[start])\n",
    "    start = start + 1\n",
    "    features_all.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[153,   9, 163, ...,   0,  14, 255],\n",
       "        [154,  10, 162, ...,   0,  37, 255],\n",
       "        [153,   8, 164, ...,   0,  12, 255],\n",
       "        ...,\n",
       "        [147,  21,  99, ...,   0,  45, 255],\n",
       "        [151,  25, 105, ...,   0, 189, 255],\n",
       "        [154,  29, 121, ...,   0, 146, 255]], dtype=uint8),\n",
       " ['drilling', 'jackhammer'],\n",
       " '/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/uniform/soundscape_train_1_uniform0.wav']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### with open(os.path.join('/home/t-anmend/UrbanSound8K/soundscapes/train_1/','train1_features_3000.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/','train1_features_12000.txt'),'wb') as f:\n",
    "    pickle.dump(features_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/','train1_features_12000.txt'),'rb') as f:\n",
    "    features_file_train1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[153,   9, 163, ...,   0,  14, 255],\n",
       "        [154,  10, 162, ...,   0,  37, 255],\n",
       "        [153,   8, 164, ...,   0,  12, 255],\n",
       "        ...,\n",
       "        [147,  21,  99, ...,   0,  45, 255],\n",
       "        [151,  25, 105, ...,   0, 189, 255],\n",
       "        [154,  29, 121, ...,   0, 146, 255]], dtype=uint8),\n",
       " ['drilling', 'jackhammer'],\n",
       " '/home/t-anmend/UrbanSound8K/soundscapes/train_12000/2_5/uniform/soundscape_train_1_uniform0.wav']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_file_train1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stats for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_directory,'train1_features.txt'),'rb') as f:\n",
    "    features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = []\n",
    "for i in range(len(features)):\n",
    "    features_all.append(features[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_std = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_median = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_kurtosis = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_min = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_max = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "train_skew = np.zeros((len(features_all),features_all[0][0].shape[0]))\n",
    "\n",
    "for i in range(len(features_all)):\n",
    "\n",
    "    train_means[i] = np.mean(features_all[i], axis=0)\n",
    "    train_std[i] = np.std(features_all[i], axis=0)\n",
    "    train_median[i] = np.median(features_all[i], axis=0)\n",
    "    train_kurtosis[i] = scipy.stats.kurtosis(features_all[i], axis=0)\n",
    "    train_skew[i] = scipy.stats.skew(features_all[i], 0)\n",
    "    train_min[i] = np.amin(features_all[i], 0)\n",
    "    train_max[i] = np.amax(features_all[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_means.shape)\n",
    "print (train_std.shape)\n",
    "print (train_median.shape)\n",
    "print (train_min.shape)\n",
    "print (train_max.shape)\n",
    "print (train_kurtosis.shape)\n",
    "print (train_skew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute = np.concatenate((train_means,train_std,train_median,train_min,train_max,train_kurtosis,train_skew), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_compute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i = []\n",
    "\n",
    "for i in range(feature_compute.shape[0]):\n",
    "    feature = []\n",
    "    feature.append(feature_compute[i])\n",
    "    feature.append(features[i][1])\n",
    "    feature.append(features[i][2])\n",
    "    \n",
    "    features_i.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_i[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_directory,'train1_stats_features.txt'),'wb') as f:\n",
    "    pickle.dump(features_i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
